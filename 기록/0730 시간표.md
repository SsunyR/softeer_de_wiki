# 0730

- Local Spark 연결

- 필요한 라이브러리 다운받고 다음과 같이 설정.

  - iterm

        brew install openjdk@21
        brew install apache-spark

  - terminal

        pip install jupyterlab pyspark ipykernel findspark

  - jupyter notebook

        import findspark

        os.environ['SPARK_HOME'] = '/opt/homebrew/Cellar/apache-spark/4.0.0/libexec'
        os.environ['JAVA_HOME'] = '/opt/homebrew/Cellar/openjdk@21/~~~/'

        findspark.init()

        from pyspark.sql import SparkSession

        spark = SparkSession.builer \
        .appName("myspark") \
        .master("local[*]") \
        .config('spark.driver.host', '127.0.0.1') \
        .getOrCreate()

        spark

- 같은 테이블 두 번 조인 시 문제
  - 문제 코드

        df_with_zone = df_with_date.join(
            taxi_zone,
            df_with_date.PULocationID == taxi_zone.LocationID,
            how="left"
        ).select(
            df_with_date["*"],
            taxi_zone["Borough"]
        ).withColumnRenamed("Borough", "PULocation")

        df_with_zone = df_with_zone.join(
            taxi_zone,
            df_with_zone.DOLocationID == taxi_zone.LocationID,
            how="left"
        ).select(
            df_with_zone["*"],
            taxi_zone["Borough"]
        ).withColumnRenamed("Borough", "DOLocation")

    - join 연산 이후에 df_with_zone 테이블은 PULocationID와 taxi_zone의 LocationID를 동일시 하는듯 함.
    -> 모호성 이슈가 발생해 조인이 안됨.
    -> taxi_zone에 alias를 부여한 복제 DF를 만들어 조인.