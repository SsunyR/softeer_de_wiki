# 0818 강의

## Catalyst Optimizer

- Rule Based Optimizer
  - Analise with Catalog
  - Logical Plan
  - Physical Plan with Tungsten

- Physical Plan Generation
  - 하나의 Optimized Logical Plan에 대해 여러 개의 Physical Plan
    - Data 모양에 따라 Cost가 달라질 가능성이 있어 비교해 가장 적은 비용으로
    - Data 모양은 어디서?
- Code Generation
  - Whole-Stage Code Generation: 스테이지 단위로 함수를 통으로 제작

- Dynamic Partition Pruning
  - Columnar Data라서 Column의 추가와 삭제가 가능
  - 처리 데이터의 크기를 줄이는게 목적

## Adaptive Query Execution

- *Dynamic*
- 실행시간에 데이터 통계를 보고 실행계획을 동적 튜닝
  - Data Skew: 한 노드가 다른 노드에 비해 현저히 느림
- 기본적으로 Storage와 Computing layer는 분리됨
  - 데이터의 모양을 실행시간에 판단할 수 밖에 없음.
- *Query Stage*
  - MapOutputStatistics -> runtime statistics 제공

- *Logical Plan*을 수정

## Parallelism on Reducers

- Post-Shuffle Partitions

## Join Strategy

- shuffle이 거의 무조건 일어남 -> 성능에 큰 영향

- ShuffleHashJoin
  - Dynamic Filter
  - Hash table 크기가 작아서 메모리에 다 들어갈 수 있을 때
- SortMergeJoin
  - reduce comparation
- BroadcastHashJoin
  - Hash table 크기가 작아서 메모리에 다 들어갈 수 있을 때
  - Based on Rule
\
- Skewed Join

## AQE Not Needed

- Runtime statistics overhead 시간이 Job execution 시간과 별 차이가 없는 작업
- Well Optimized Jobs

### Join Followed by a Shuffle

### Shuffling After a Join

- Not always

### 결론

- Spark Optimizer가 수행하지 못한 최적화는 사람이 해야됨.
  - Spark Executor를 보고 문제를 인지할 수 있어야 함
  - Spark Optimizer가 담당하는 최적화 작업을 알아야 문제를 파악할 수 있음
  - Data Engineer에게도 Data Analysis 능력이 필요

## 자소서

- 교육을 통해 느낀점
- 발표자료
- 제출 형식은 pdf
