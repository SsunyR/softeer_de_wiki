# 시간표

2시부터 spark 클러스터 구성

이미지 찾다가 그냥 spark 사용.
latest

/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master 를 사용해 master, worker 노드를 설정할 수 있지만
/opt/spark/bin/start-master.sh, start-worker.sh 를 사용하기로 함.

이미지에 파이썬은 설치되어 있으나 pyspark가 없음.
docker exec -it master-node bash를 통해 들어가 설치하려 했는데 권한 오류가 남
docker exec --user root -it master-node bash 를 통해 root로 들어가 설치해봄
설치 잘 돼서 그냥 Dockerfile로 pyspark 설치 된 이미지 만듦.
spark 유저도 sudoable하게 만듦.

spark-submit 은 잘 되는데 application running 정보가 안보임.
hostname문제인 듯? -> 아님. 뭐가 문제임?